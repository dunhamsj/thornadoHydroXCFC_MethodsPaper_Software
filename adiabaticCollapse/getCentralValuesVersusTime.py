#!/usr/bin/env python3

import os
from datetime import datetime
import numpy as np
import multiprocessing as mp
import yt
yt.funcs.mylog.setLevel(40) # Suppress yt warnings

import globalVariables as gv

from myUtilitiesModule import getPlotfileNumberArray, getMesh_1d, readDensityDecadesFile

plotfileDirectoryRoot \
  = gv.dataDirectory + 'adiabaticCollapse/'
dataDirectory \
  = plotfileDirectoryRoot + 'processedData/'

suffixAMR = [ '_AMR_dr0.25km', '_AMR_dr0.50km', '_AMR_dr1.00km' ]
suffix = suffixAMR

suffixUni = [ '_Uni_dr0.50km', '_Uni_dr1.00km' ]
suffix += suffixUni

suffixx = [ '_AMR_dr0.25km_nLevels04', '_AMR_dr0.25km_HLLC' ]
suffix += suffixx

fields = [ 'PF_D', 'AF_T', 'AF_Ye', 'AF_S' ]

ID = 'AdiabaticCollapse_XCFC'
plotfileBaseName = ID + '.plt'

# Interpolate to origin to get central value
origin = [np.array([0.0,np.pi/2.0,np.pi])];

nProcs = mp.cpu_count()

verbose = True

for s in range( len( suffix ) ) :

    plotfileDirectory \
      = plotfileDirectoryRoot \
          + '{:}{:}/'.format( ID, suffix[s] )

    plotfileNumberArray \
      = getPlotfileNumberArray \
          ( plotfileDirectory, \
            plotfileBaseName )

    nSS = plotfileNumberArray.shape[0]
    SS  = np.linspace( 0, plotfileNumberArray.shape[0]-1, nSS, dtype = np.int64 )

    SSw = np.array_split( SS, nProcs )

    densityDecadesFileName \
      = dataDirectory \
          + 'DensityDecades{:}.dat'.format( suffix[s] )

    ib, tb, rhob, indd, pfnd \
      = readDensityDecadesFile( densityDecadesFileName )

    def worker( SSw, procnum, return_dict ):

        nSSl = SSw.shape[0]

        tmtb = np.empty( nSSl )
        qC   = np.empty( (len(fields),nSSl) )

        for iSS in range( nSSl ):

            if ( verbose ) :
                print( '\r  {:d}/{:d}'.format( iSS, nSSl ), end = '\r' )
    
            plotfileName \
              = plotfileDirectory + plotfileBaseName \
                  + str( plotfileNumberArray[SSw[iSS]] ).zfill( 8 )
    
            ds = yt.load( plotfileName )
            time = ds.current_time.to_ndarray()

            for i in range( len( fields ) ):
    
                data \
                  = np.copy( ds.find_field_values_at_points \
                               ( ("boxlib",fields[i]), origin ) )[0]
    
                qC[i,iSS] = data
    
                tmtb[iSS] = time - tb # Hack
    
            del ds

        return_dict[procnum] = [ tmtb, qC ]

        return

    print( '\n  Running getCentralValuesVersusTime for {:}' \
           .format( 'AdiabaticCollapse_XCFC{:}'.format( suffix[s] ) ) )
    print(   '  --------------------------------------' )

    # Parallel stuff from
    # https://stackoverflow.com/questions/10415028/
    # how-can-i-get-the-return-value-of-a-function-passed-to
    # -multiprocessing-process
    manager = mp.Manager()
    return_dict = manager.dict()
    jobs = []
    for i in range( nProcs ):
        p = mp.Process( target = worker, args = ( SSw[i], i, return_dict ) )
        jobs.append(p)
        p.start()

    for proc in jobs:
        proc.join()

    tmtb = []
    qC   = [ [] for i in range( len( fields ) ) ]

    for i in range( nProcs ):
        dtmp = return_dict[i]
        tmtb.append( dtmp[0] )
        for j in range( len( fields ) ):
            qC[j].append( dtmp[1][j] )

    tmtb = np.array( np.concatenate( tmtb ), dtype = np.float64 )
    arg  = np.argsort( tmtb )
    tmtb = tmtb[arg]
    
    qCtmp = qC
    qC = np.empty( (len(fields),nSS), dtype = np.float64 )
    for j in range( len( fields ) ):
        qC[j] = np.array( np.concatenate( qCtmp[j] ), dtype = np.float64 )

    filename \
      = dataDirectory + 'CentralValues{:}.dat'.format( suffix[s] )
    header \
      = 'Filename: {:}\nGenerated by {:}\non {:}\nt - tb [ms], DC [g/cm^3], TC [K], YC, SC [kB/baryon]' \
        .format( filename, __file__, datetime.today() )
    np.savetxt( filename, np.vstack( ( tmtb, qC[0], qC[1], qC[2], qC[3] ) ), \
                header = header )
    os.system( 'chmod 444 {:}'.format( filename ) )
    print( ' Saved {:}'.format( filename ) )

os.system( 'rm -rf __pycache__' )
